
<head> 
  <!-- import aframe and then ar.js with image tracking / location based features -->
<script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"></script>
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>
<!-- <script src="https://raw.githack.com/fcor/arjs-gestures/master/dist/gestures.js"></script> -->
<script>
  window.onload = function () {
    var para = document.getElementsByTagName("animated-model")[0];
        var atts = para.attributes;
        console.log(atts);
    document
      .querySelector(".say-hi-button")
      .addEventListener("click", function () {
        // here you can change also a-scene or a-entity properties, like
        // changing your 3D model source, size, position and so on
        // or you can just open links, trigger actions...
        alert("Hi there!");
      
      });
  };
</script>

<!-- style for the loader -->
<style>
  .buttons {
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 5em;
    display: flex;
    justify-content: center;
    align-items: center;
    z-index: 10;
  }

  .say-hi-button {
    padding: 0.25em;
    border-radius: 4px;
    border: none;
    background: white;
    color: black;
    width: 4em;
    height: 2em;
  }
  .arjs-loader {
    height: 100%;
    width: 100%;
    position: absolute;
    top: 0;
    left: 0;
    background-color: rgba(0, 0, 0, 0.8);
    z-index: 9999;
    display: flex;
    justify-content: center;
    align-items: center;
  }

  .arjs-loader div {
    text-align: center;
    font-size: 4em;
    color: rgb(255, 230, 0);
    font-weight: bold;
  }
  .a-loader-title {
    color: red;
  }
  
</style>
</head>

<body style="margin : 0px; overflow: hidden;">
<!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->


  <div class="arjs-loader">
    <div>Cargando</div>

  </div>

  <div class="buttons">
    <button class="say-hi-button" >SAY HI!</button>
  </div>

  <!-- a-frame scene -->
  <a-scene
    arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
    embedded
    renderer="logarithmicDepthBuffer: true;"
    vr-mode-ui="enabled: false"
    gesture-detector
    id="scene"
  >
    <!-- a-nft is the anchor that defines an Image Tracking entity -->
    <!-- on 'url' use the path to the Image Descriptors created before. -->
    <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
    <a-nft
      type="nft"
      url="https://walle-api-madam-birras.herokuapp.com/index"
      smooth="true"
      smoothCount="10"
      smoothTolerance=".01"
      smoothThreshold="5"
      raycaster="objects: .clickable"
      emitevents="true"
      cursor="fuse: false; rayOrigin: mouse;" >
      
      <a-box 
        class="clickable"
        gesture-handler="minScale: 0.25; maxScale: 10" 
        id="animated-model" 
        position="70 0 -200" 
        scale="400 2 500" 
        src="https://walle-api-madam-birras.herokuapp.com/Cube_BaseColor.jpg" 
        shadow ></a-box>
    </a-nft>
    <!-- static camera that moves according to the device movemenents -->
    <a-entity camera></a-entity>
  </a-scene>
</body>




